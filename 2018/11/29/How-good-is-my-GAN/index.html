<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="gan,">










<meta name="description" content="How good is my GAN 学习笔记&amp;emsp;&amp;emsp;GAN是当今最流行的图像生成方法之一。以前的令人印象深刻的结果都是通过目视检查得到证实的，直到最近才出现了一些定量标准。作者认为现有的办法是不够的，需要与你目前的任务相适应才好。在本篇文章中作者提出了两个基于图像分类网络的两个测量指标——GAN-train和GAN-test，这些分别近似GAN的召回率（多样性）和精度（图像的质">
<meta name="keywords" content="gan">
<meta property="og:type" content="article">
<meta property="og:title" content="How good is my GAN">
<meta property="og:url" content="http://yoursite.com/2018/11/29/How-good-is-my-GAN/index.html">
<meta property="og:site_name" content="ZhuYue&#39;s Home">
<meta property="og:description" content="How good is my GAN 学习笔记&amp;emsp;&amp;emsp;GAN是当今最流行的图像生成方法之一。以前的令人印象深刻的结果都是通过目视检查得到证实的，直到最近才出现了一些定量标准。作者认为现有的办法是不够的，需要与你目前的任务相适应才好。在本篇文章中作者提出了两个基于图像分类网络的两个测量指标——GAN-train和GAN-test，这些分别近似GAN的召回率（多样性）和精度（图像的质">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="https://user-images.githubusercontent.com/44546944/50212937-371c2280-03b7-11e9-9faf-b2229773c20a.jpg">
<meta property="og:image" content="https://user-images.githubusercontent.com/44546944/49210164-53035880-f3f7-11e8-8bff-c5b2642c7e77.PNG">
<meta property="og:image" content="https://user-images.githubusercontent.com/44546944/49487913-760e8c00-f87f-11e8-89fe-58154aac6ded.PNG">
<meta property="og:image" content="https://user-images.githubusercontent.com/44546944/50195800-93615100-037b-11e9-96e4-6c83d4282e9f.PNG">
<meta property="og:image" content="https://user-images.githubusercontent.com/44546944/50206660-0cc26900-03a7-11e9-8474-9182c5bba8dd.PNG">
<meta property="og:image" content="https://user-images.githubusercontent.com/44546944/50207437-72aff000-03a9-11e9-997e-b87cb699a53d.PNG">
<meta property="og:image" content="https://user-images.githubusercontent.com/44546944/50210292-b0644700-03b0-11e9-9806-deae66b6b8cb.PNG">
<meta property="og:image" content="https://user-images.githubusercontent.com/44546944/50210776-f968cb00-03b1-11e9-8527-755ff265ff61.PNG">
<meta property="og:image" content="https://user-images.githubusercontent.com/44546944/50210995-7c8a2100-03b2-11e9-9f74-b36b1c4309be.PNG">
<meta property="og:image" content="https://user-images.githubusercontent.com/44546944/50212254-8b260780-03b5-11e9-9d25-4ec1c91e9621.PNG">
<meta property="og:updated_time" content="2018-12-20T08:33:14.222Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="How good is my GAN">
<meta name="twitter:description" content="How good is my GAN 学习笔记&amp;emsp;&amp;emsp;GAN是当今最流行的图像生成方法之一。以前的令人印象深刻的结果都是通过目视检查得到证实的，直到最近才出现了一些定量标准。作者认为现有的办法是不够的，需要与你目前的任务相适应才好。在本篇文章中作者提出了两个基于图像分类网络的两个测量指标——GAN-train和GAN-test，这些分别近似GAN的召回率（多样性）和精度（图像的质">
<meta name="twitter:image" content="https://user-images.githubusercontent.com/44546944/50212937-371c2280-03b7-11e9-9faf-b2229773c20a.jpg">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '5.1.4',
    sidebar: {"position":"left","display":"always","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2018/11/29/How-good-is-my-GAN/">





  <title>How good is my GAN | ZhuYue's Home</title>
  








</head>

<body itemscope="" itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">ZhuYue's Home</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">ZhuYue's Home</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            归档
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/11/29/How-good-is-my-GAN/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="朱越">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/logo.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ZhuYue's Home">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">How good is my GAN</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-11-29T15:54:22+08:00">
                2018-11-29
              </time>
            

            

            
          </span>

          

          
            
          

          
          
             <span id="/2018/11/29/How-good-is-my-GAN/" class="leancloud_visitors" data-flag-title="How good is my GAN">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">阅读次数&#58;</span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p><img src="https://user-images.githubusercontent.com/44546944/50212937-371c2280-03b7-11e9-9faf-b2229773c20a.jpg" alt=""></p>
<h1 id="How-good-is-my-GAN-学习笔记"><a href="#How-good-is-my-GAN-学习笔记" class="headerlink" title="How good is my GAN 学习笔记"></a><strong>How good is my GAN 学习笔记</strong></h1><p>&emsp;&emsp;GAN是当今最流行的图像生成方法之一。以前的令人印象深刻的结果都是通过目视检查得到证实的，直到最近才出现了一些定量标准。作者认为现有的办法是不够的，需要与你目前的任务相适应才好。在本篇文章中作者提出了两个基于图像分类网络的两个测量指标——GAN-train和GAN-test，这些分别近似GAN的召回率（多样性）和精度（图像的质量）。我们基于这两个指标评估了一些最近的GAN方法，并证明了性能的明显差异。此外，我们还观察到，数据集的难度从CIFAR10/CIFAR100到ImageNet的增加，和GANs的质量呈反比关系，这从我们的测量数据中可以明显看出。</p>
<h2 id="1-引言"><a href="#1-引言" class="headerlink" title="1 引言"></a><strong>1 引言</strong></h2><p>&emsp;&emsp;GAN是由一对相互竞争的神经网络（生成器和鉴别器）组成的深度神经网络结构。该模型通过交替优化两个目标函数来训练。生成器G的任务是学习生成与真实图像相似的样本，鉴别器D的任务是学习更好地辨别真实和虚假数据。这种模式具有巨大的潜力，因为它可以学习生成任何数据分布。这种方法已经在一些计算机视觉问题上得到了成功的应用，比如文本到图像转换和风格迁移，超分辨率以及逼真自然图像生成。</p>
<p>&emsp;&emsp;自从GAN提出以来，这几年提出了许多GAN的变体，比如提高生成图像质量的，稳定训练过程的。GANs也经过了修改，可以根据附加信息(例如类标签)生成给定类的图像。有许多方法可以做到这一点:从将标签y连接到生成器输入z或中间特征映射，到使用条件批处理规范化，以及使用辅助分类器来增加鉴别器。由于文献中经常提出几个这样的变体，一个关键问题是如何评价这些模型，并将其相互比较。<br> <img src="https://user-images.githubusercontent.com/44546944/49210164-53035880-f3f7-11e8-8bff-c5b2642c7e77.PNG" alt="1"> </p>
<p><strong>图1</strong> SNGAN模型生成的逼真图像，与真实图像相比，这些图像很难以主观评估。我们新的基于图像分类精度的测量方法(这里显示了GAN-train)克服了这个问题，显示了真实图像和生成图像之间的明显差异。</p>
<p>&emsp;&emsp;GANs生成的图像的评估和比较具有挑战性。这在一定程度上是由于缺乏显式的可能性度量，而显式的可能性度量在可比较的概率模型中很常见。因此，对于GANs合成的图像，以往的许多工作仅仅依靠主观的视觉评价。从图1中SNGAN生成的样本图像可以看出，不可能通过主观评价来准确判断其质量。近两年的工作已经开始通过定量评价GAN的方法来应对这一挑战。</p>
<p>&emsp;&emsp;Inception score(IS)和FID被认为是与生成图像的视觉质量相关的临时测量。IS通过计算图像产生的（logit）响应与边缘分布之间的KL散度来度量生成图像的质量，即所有生成的图像的平均响应，使用一个通过ImageNet上训练的Inception网络。换句话说，IS不会将样本与目标分布进行比较，并且仅限于量化生成样本的多样性。FID比较真实图像和生成图像之间的初始激活（初始网络的倒数第二层的响应）然而，这种比较将真实图像和生成的图像的激活近似为高斯分布，计算它们的均值和协方差，但是它们太粗糙而无法捕捉细微的细节。这两种方法都依赖于ImageNet预训练的Inception网络，这对于其他数据集（如人脸和生物医学成像）来说并非理想。总的来说，IS和FID是评估训练进展情况的有用方法，但它们不能保证与实际任务的性能相关。正如我们在第5节中讨论的那样，与我们的措施不同，这些措施不足以精细地分辨最先进的GAN模型(see SNGAN vs WPGAN-GP(10M) in Table 2 forexample)</p>
<p>&emsp;&emsp;另一种评估方法是根据精确度和召回率计算生成的样本到实际数据流形的距离。这里，高精度意味着生成的样本接近于数据流形，高召回率表明生成器输出的样本覆盖流形良好。这些测量仍然是理想的，因为它们不可能在自然图像数据上计算，其流形是未知的。实际上，[32]中的计算仅限于使用由灰度三角形组成的合成数据。另一种比较GAN模型的距离建议是Wasserstein距离切片(SWD)。SWD是真实图像与生成图像之间的Wasserstein-1距离的近似，它被计算为从这些图像的拉普拉斯金字塔表示中提取的局部图像斑块之间的统计相似性。如第5节所示，SWD的信息量低于我们的评估措施。</p>
<p>&emsp;&emsp;在本文中，我们提出了新的评价方法，通过GAN-train和GAN-test的分数来比较类条件GAN体系结构。对于这两种测量方法，我们都依赖于图像分类神经网络。为了计算GAN-train，我们通过一个GAN生成的图像训练一个分类网络，然后在由真实图像组成的测试集上评估其性能。直觉上，这测量的是生成图像的和真实图像分布的差异。如果学会鉴别不同类别生成图像特征的的分类网络能够正确地对真实图像进行分类，我们就可以得出生成的图像与真实图像相似的结论。换句话说，GAN-train是一种类似于召回率的测度，作为一个好的GAN-train性能，表示为生成的样本具有足够的多样性。然而，也需要同样的足够的精度，否则样本质量会影响到分类器。</p>
<p>&emsp;&emsp;我们第二个度量，GAN-test，是一个在真实图像上训练并用生成图像进行评估的网络的准确性。该方法与预测相似，具有较高的值，表明生成的样本是自然图像(未知)分布的真实近似。除了这两个测定，我们研究了GANs生成的图像对训练数据的实用性。这可以解释为生成的图像的多样性的度量。特别是在主观检查不足的情况下，图一中的GAN-train度量说明了我们的评估方法的效用。我们将会在第三部分详细的讨论这些度量。</p>
<p>&emsp;&emsp;正如我们在第5节和补充材料和技术报告[5]附录中广泛的实验结果所显示的，与以前讨论的所有测量方法相比，这些测量方法在评估GAN方面提供了更多的信息，包括人们研究没有结论性的情况。特别是，我们评估了两种最先进的GAN模型:WGAN-GP[20]和SNGAN[36]，以及其他生成模型[45,47]，为了提供基本比较。在MNIST[30]、CIFAR10、CIFAR100[28]和ImageNet[14]数据集上评价图像分类的性能。实验结果表明，随着数据集复杂度的增加，GAN生成的图像的质量明显下降。</p>
<h2 id="2-相关工作"><a href="#2-相关工作" class="headerlink" title="2 相关工作"></a><strong>2 相关工作</strong></h2><p>&emsp;&emsp;我们现有的定量评估GANs的度量基于Inception网络的分数，Is和FID，一个基于Wasserstein距离的测度，精度和召回率分数，以及一种数据扩充的技术。</p>
<h3 id="2-1-Inception-score"><a href="#2-1-Inception-score" class="headerlink" title="2.1 Inception score"></a><strong>2.1 Inception score</strong></h3><p>&emsp;&emsp;评估GANs最常用的方法之一是Inception score。它使用一个初始化网络[50]在ImageNet上预先训练来计算生成的图像的逻辑。分数是由以下公式给出：<br> <img src="https://user-images.githubusercontent.com/44546944/49487913-760e8c00-f87f-11e8-89fe-58154aac6ded.PNG" alt="2"> </p>
<p>其中X是从学习到的生成器$ P_g $分布中采样得到的生成图像，E是生成图像集的期望，$ D_{KL} $是条件类分布$ p(y|x) $和边缘分布$ p(y) = E_{x\sim p_g}[p(y|x)] $之间的$ KL $散度根据定义，初始分数根本不考虑真实图像，因此无法测量生成器的近似程度如何。这个分数仅限与测量生成图像的多样性。正如[8]中指出的，它的一些其他限制是，对Inception网络权重的小变化非常的敏感，并且分数差异很大。</p>
<h3 id="2-2-Frechet-Inception-distance"><a href="#2-2-Frechet-Inception-distance" class="headerlink" title="2.2 Frechet Inception distance"></a><strong>2.2 Frechet Inception distance</strong></h3><p>&emsp;&emsp;最近提出的FID[22]比较的是真实图像和生成图像间的 Inception 激活值（Inception 网络中倒数第二层的响应）这两个分布都被建模为多维高斯，由它们各自的均值和协方差参数化。两个高斯分布之间的距离测度定义为:</p>
<script type="math/tex; mode=display">d^2((m_r,C_r),(m_g,C_g)) = {||m_r-m_g||}^2+Tr(C_r+C_g-2{C_rC_g}^{\frac{1}{2}}).............(2)</script><p>其中$（m_r,C_r）,(m_g,c_g) $分别表示真实图像分布和生成图像分布。FID与IS成负相关，来自前面讨论过的问题。</p>
<p>&emsp;&emsp;这两种基于Inception测量方法，不能将图像质量与图像多样性区分开来。例如，低IS或高的FID值可能是因为生成的图像要么不真实(图像质量低)，要么彼此太相似(多样性低)，无法分析原因。相比之下，我们的测量可以区分出生成的图像在什么时候变得不那么多样化，什么时候图像质量变差。</p>
<h3 id="2-3-其他评价方法"><a href="#2-3-其他评价方法" class="headerlink" title="2.3 其他评价方法"></a><strong>2.3 其他评价方法</strong></h3><p>&emsp;&emsp;切瓦瑟斯坦距离（SWD）[25]被用来评估高分辨率GANs。它是从真实图像和生成图像的拉普拉斯金字塔表示中提取到局部图像块并计算出的多尺度统计相似性。每幅图像中每层拉普拉斯金字塔一共提取128个7*7个局部斑块。虽然SWD是一种有效的近似，使用随机投影[44]，真实图像和生成图像之间的Wasserstein-1距离，但它在比较各种GAN模型时的效用是有限的，并非所有GAN模型都能产生高分辨率图像（ 见第5节中的评估）。</p>
<p>&emsp;&emsp;在GANs环境下，通过构造一个综合数据流形，引入了精度和召回率测度[32]。通过找到它到流行最近点的距离，使得计算一个图像样本（生成或是真实的）到流形距离成为可能。在这个合成设置中，精度被定义为生成样本的分数，其到流形的距离低于某个阈值。另一方面，召回率是通过考虑一组测试样本来计算的。首先，通过反转发生器G，每个测试样本X的潜在表示Z由梯度下降估计。然后，召回率是通过L2到G（z）的距离低于阈值的测试样本的分数.高召回率等价于GAN捕捉大部分的流行，高精度意味着生成的样本接近流形。但是由于数据流形是未知的，他们对真实图像是不切实际的，而且它们的使用仅限于对合成数据的评估。</p>
<h3 id="2-4-数据增强"><a href="#2-4-数据增强" class="headerlink" title="2.4 数据增强"></a><strong>2.4 数据增强</strong></h3><p>&emsp;&emsp;增强训练数据是学习sheng神经网络的重要组成部分。这可以通过增强训练集[29]的大小或者将增量直接合并到潜在空间[54]来实现。一种流行的技术是通过较小的数据转换来增加训练集的大小，这导致性能提升，例如，用于图像分类[29].GANs提供了一种用生成的样本来增强训练数据的自然方法。实际上，GAN已被用于以半监督的方式训练分类网络[13,52]或促进领域适用[10]。现代GAN生成的图像足够逼真，可以提高应用程序的性能，例如生物医学成像[11,18],人物识别[58]和图像增强[55].它们还可用于细化由合成图像组成的训练集，用于眼睛注视和手姿势估计等应用[49]。GANs还用于学习复杂的三维分布，并取代物理[39][42]和神经科学[38]中计算密集型模拟。理想情况下，GANs应该能够用不同的变体重新创建训练集。这可以不断的学习，通过使用压缩数据集的方法，不会因为添加了新类而导致灾难性的遗忘[48]。我们将研究GANs在具有数据扩充的图像分类网络训练中的效果，将它作为评估措施进行分析。<br><img src="https://user-images.githubusercontent.com/44546944/50195800-93615100-037b-11e9-96e4-6c83d4282e9f.PNG" alt="3"></p>
<p>图2 GAN-train和GAN-test说明。GAN-train利用GAN生成的图像训练分类网络，并用真实图像测试性能。这评价了GAN图像的多样性和真实性。GAN-test通过真实图像训练分类网络并且用GAN生成图像测试分类网络。这测试的GAN生成图像的真实性。</p>
<p>综上所述，生成模型的评估并不是一个简单的任务，尤其是对于GANs这样的模型。我们的GAN-train和GAN-test基于性能的度量方法为这个问题带来了一个新的维度，并通过广泛的分析表明它们与上述所有方案是互补的。</p>
<h2 id="3-GAN-train和GAN-test"><a href="#3-GAN-train和GAN-test" class="headerlink" title="3 GAN-train和GAN-test"></a><strong>3 GAN-train和GAN-test</strong></h2><p>&emsp;&emsp;条件GAN模型的一个重要特征是，生成的图像不仅要真实，而且要能够识别来自给定类的图像。一个能很好地捕获目标分布的最优GAN可以生成一组新的图像$ S_g $，与原始训练集$ S_t $难以区分。假设这两个集合具有相同的大小，则对其中任何一个进行训练的分类器应该产生大致相同的验证准确度。当数据集足够简单时，例如MNIST<a href="也请参阅5.2节">48</a>，确实如此。受此最优GAN特性的驱动，我们设计了两个评分来评估GANs，如图2所示。<br>&emsp;&emsp;GAN-train是在$ S_g $上训练的分类器的准确度，并且在真实图像$ S_v $的验证集上进行测试。当GAN不完美时，GAN-train准确度将低于在$S_t$上训练的分类器的验证精度。这可能是由于许多原因造成的，例如(i)模式下降降低了$ S_g $相对于$ S_t $的多样性，(ii)生成的样本不够真实，无法让分类器学习到相关特征，(iii) GANs会混淆类，混淆分类器。不幸的是，GAN失败是很难判断的。当GAN-train准确率接近验证准确率时，说明GAN图像质量高，与训练集一样多样化。正如我们将在5.3节中展示的，多样性随生成图像的数量而变化。我们将在本节最后讨论的评估中对此进行分析。</p>
<p>&emsp;&emsp;GAN-test是在原始训练集$S_t$上训练的分类器的准确性，但是在$S_g$上测试。如果GAN学习得很好，这将是一个简单的任务，因为这两个集合具有相同的分布。理想情况下，GAN-test应该接近验证精度。如果它显着更高，则意味着GAN过度拟合，只是简单地记忆训练集。相反，如果GAN值明显较低，则表明GAN不能很好地捕获目标分布，图像质量较差。请注意，这种方法不能捕捉样本的多样性，因为一个模型完全记住一个训练图像将得到非常好的结果。GAN-test的精度与[32]中的精度得分有关，它量化了生成的图像与数据流形的距离。</p>
<p>&emsp;&emsp;为了深入了解GAN生成的图像的多样性，我们使用生成的不同大小的集合来测量GAN-train精度，并将其与在对应的大小的实际数据上训练的分类器的验证精度进行比较。如果所有生成的图像都是完美的，那么GAN-train的大小等于具有缩小尺寸训练集的验证精度，将是对$ S_g $中的不同图像的数量的良好估计。在实践中，我们观察到GAN-train精度与一定数量的gan生成的样本饱和。(见5.3节讨论的图4(a)和4(b))。这是一个GAN多样性的度量，类似于从[32]收回，度量被GAN覆盖的数据流形的百分比。</p>
<h2 id="4-数据集和方法"><a href="#4-数据集和方法" class="headerlink" title="4 数据集和方法"></a><strong>4 数据集和方法</strong></h2><p>&emsp;&emsp;为了比较不同的GAN方法和PixelCNN++，我们使用了几个具有越来越多标签的图像分类数据集：MNIST [30]，CIFAR10 [28]，CIFAR100 [28]和ImageNet1k [14]。CIFAR10和CIFAR100在训练集中都有50k 32<em>32 RGB图像，在验证集中都有10k图像。CIFAR10有10个类，CIFAR100有100个类。ImageNet1k拥有1000个类，1.3M的训练和50k的验证图像。我们在实验中将原始的ImageNet图像降采样到两个分辨率，即64</em>64和128<em>128。MNIST拥有10类28</em>28灰度图像，其中60k样本用于训练，10k样本用于验证。</p>
<p>&emsp;&emsp;我们从GAN训练中排除CIFAR10/CIFAR100/ImageNet1k验证图像，以评估测试准确性。这在许多GAN论文中没有做过，这可以解释is和FID分数与这些论文中报告的分数相比存在的微小差异。</p>
<h3 id="4-1-评估方法"><a href="#4-1-评估方法" class="headerlink" title="4.1 评估方法"></a><strong>4.1 评估方法</strong></h3><p>&emsp;&emsp;在文献中过多的GAN模型中，很难选择最好的模型，特别是因为适当的超参数调整似乎可以使所有主要的GAN在非常接近的性能范围内，如研究中所述[32]。我们选择对Wasserstein GAN (WGAN-GP)和SNGAN进行分析，后者是目前文献中最广泛接受的模型之一，SNGAN是最近的一个模型，它在ImageNet上显示了最先进的图像生成结果。此外，我们还包括两个基础的生成模型，DCGAN[45]和PixelCNN++[47]。我们总结了下面实验分析中包含的所有模型，并在附录[5]中给出了实现细节。</p>
<p>&emsp;&emsp;<strong>Wasserstein GAN</strong>. WGAN用一个判别器的评估Wasserstein-1代替鉴别器分离真实图像和生成图像。WGANs在与经典的GAN模型[19]相比较方面的成功可以归结为两个原因。首先，生成器的优化更容易，因为损失函数的梯度比其GAN损失函数更好。其次，实证结果表明，WGAN值函数与样本质量的相关性优于GANs[7]。</p>
<p>&emsp;&emsp;为了估计真实图像分布和生成图像分布之间的Wasserstein-1距离，鉴别器损失函数必须是一个K-Lipschitz函数。原始论文[7]提出了通过剪裁权值来约束批评家，以满足Lipschitz的这一要求。然而，这会导致不稳定的训练或产生不好的样本[20]。裁剪权值的一种替代方法是使用梯度惩罚作为正则化器来执行Lipschitz约束。特别地，我们惩罚了鉴别器损失函数梯度相对于其输入的范数。这证明了几个GAN体系结构的稳定培训[20]。</p>
<p>&emsp;&emsp;在我们实验数据中我们使用梯度惩罚WGAN的变量，并在本文的其余部分将其称为WGAN- gp。标签调节是使用图像分类训练数据中可用标签的有效方法[41]。在ACGAN [41]之后，我们将噪声输入z与生成器中的类标签连接起来，并修改鉴别器以产生源和标签上的概率分布。<br><strong>SNGAN.</strong>变体还分析了与训练甘斯相关的其他问题，例如鉴别器的性能控制对发电机训练的影响。由于鉴别器的训练不稳定，特别是在高维空间[36]中，发生器往往无法学习目标分布的多模态结构。更引人注目的是，当真实的支持和生成的图像分布是不相交的[6]时，生成器停止学习。这是因为鉴别器很快就学会了区分这些分布，导致鉴别器函数相对于输入的梯度变为零，从而无法进一步更新生成器模型。</p>
<p>&emsp;&emsp;SNGAN[36]引入了光谱归一化来稳定训练鉴别器。这是通过用权矩阵的谱范数对鉴别器的每一层进行归一化来实现的，权矩阵的谱范数是鉴别器的最大奇异值。Miyato等人的[36]结果表明，这种正则化方法优于梯度惩罚等其他方法，特别是在ImageNet上实现了最先进的图像合成结果。我们在评估中使用了SNGAN[37]的类条件版本。在这里，SNGAN在鉴别器网络中以投影为条件，在生成器网络中以条件批处理归一化[17]为条件。</p>
<p><strong>DCGAN.</strong>深度卷积GAN（DCGAN）是一类架构，旨在利用CNN监督学习的好处以及GAN模型的无监督学习[45]。DCGAN背后的主要原则是仅对发生器和鉴别器网络使用卷积层和批量归一化。有了这些广泛的指导方针，DCGAN的几个实例是可能的，事实上，许多实例确实存在于文献中。我们使用[41]中提供的类条件变量进行分析。</p>
<p><strong>PixelCNN++</strong>原始PixelCNN[53]属于一类生成模型，具有易于处理的似然性。它是一种深度神经网络，可以在两个空间维度上连续预测像素。使用掩蔽卷积利用全卷积网络捕获像素之间的空间依赖性。PixelCNN++在正则化、修改网络连接、提高训练效率等方面对该模型进行了改进。 </p>
<h2 id="5-实验"><a href="#5-实验" class="headerlink" title="5 实验"></a><strong>5 实验</strong></h2><h3 id="5-1-评估措施实施细则"><a href="#5-1-评估措施实施细则" class="headerlink" title="5.1 评估措施实施细则"></a><strong>5.1 评估措施实施细则</strong></h3><p>&emsp;&emsp;我们使用WGAN-GP代码[1]来计算初始值，该代码纠正了1008个类问题[8]。这个分数在5k分割中计算了10次，其平均值在我们所有的评估中都按照标准协议报告。</p>
<p>&emsp;&emsp;我们发现计算FID有两种变体。第一个是来自作者[22]的原始实现[2]，其中使用了所有真实图像和至少10k生成的图像。第二个来自SNGAN[36]实现，其中5k生成的图像与5k真实图像进行比较。在这两种情况下，协方差矩阵的估计也是不同的。因此，我们将这两个版本的FID包含在本文中，以便将来进行比较。最初的实现称为FID，而我们的5k版本的简单[4]表示为FID-5k。SWD的实施取自官方的NVIDIA存储库[3]。</p>
<h3 id="5-2-生成模型评价"><a href="#5-2-生成模型评价" class="headerlink" title="5.2 生成模型评价"></a><strong>5.2 生成模型评价</strong></h3><p><strong>MNIST.</strong>我们验证了我们的声明(来自第3节)，即GAN可以完美地在MNIST上复制一个简单的数据集。在真实MNIST数据上训练的四层卷积网分类器在测试集上实现99.3％的准确度。与此相反，SNGAN生成的图像具有99.0%的GAN-train精度和99.2%的GAN-test精度，突出了图像的高质量和多样性。</p>
<p><strong>CIFAR10.</strong>表1显示了CIFAR10上最先进的GAN模型的比较。我们观察到模型的相对排序在不同的度量指标(FID、GAN-train和GAN-test accuracy)之间是一致的。SNGAN和WGAN-GP (10M)的GAN-train和GAN-test都很高。这意味着图像质量和多样性都很好，但仍然低于真实图像（第一行92.8）。请注意PixelCNN++的多样性较低，因为在本例中GAN-test要比GAN-train高得多。这与它相对较差的初始得分和FID一致(如[32]FID中所示，FID对模式下降非常敏感)。<br><img src="https://user-images.githubusercontent.com/44546944/50206660-0cc26900-03a7-11e9-8474-9182c5bba8dd.PNG" alt="4"></p>
<p>表1:CIFAR10实验。IS:越高越好。FID和SWD:越低越好。为了更好的可读性，这里的SWD值乘以$10^3$。GAN-train和GAN-test是按百分比给出的精度(越高越好)。</p>
<p>&emsp;&emsp;注意，SWD与其他指标的相关性不大:对于WGAN-GP(尤其是swd32)来说，它始终较小。我们假设这是因为SWD近似于真实图像斑块与生成图像斑块之间的Wasserstein-1距离，这与Wasserstein GANs的优化目标有关，而与其他模型(如SNGAN)无关。这表明SWD不适合比较WGAN和其他GAN损失。 值得注意的是 WGAN-GP（10M）仅显示出比WGAN-GP（2.5M）更小的改进尽管参数数量增加了四倍。在图3中，我们在计算GAN-test测度的分类器的特征空间中，展示了CIFAR10上SNGAN生成的图像及其与训练集最近的相邻图像。请注意，SNGAN始终能够找到与生成的图像相同的类的图像，这些图像与来自训练集的图像非常接近。<br><img src="https://user-images.githubusercontent.com/44546944/50207437-72aff000-03a9-11e9-997e-b87cb699a53d.PNG" alt="5"></p>
<p>图3：第一列：SNGAN生成的图像。别的列5幅图像是来自CIFAR10-train的，并且最接近第一列的GAN生成图像。</p>
<p>&emsp;&emsp;为了突出GAN-train和GAN-test的互补性，我们按照[22]的精神，通过子采样 CIFAR10训练集来模拟一个简单的模型。GAN-train / test现在对应于在修改的数据上训练/测试分类器。我们观察到，GAN-test不像GAN-train那样对子采样不敏感(GAN-train相当于在较小的分割上训练分类器)。盐和胡椒噪声，每个图像的替换像素的1％到20％，几乎不影响GAN列车，但显着降低GAN测试（从82％到15％）。</p>
<p>&emsp;&emsp;通过对修改后的数据进行实验，我们也发现FID对于区分图像的多样性和质量的影响是不够的。例如，CIFAR10训练集与具有高斯噪声（A=5）的训练集之间的FID是27.1，而训练集与其具有相同噪声的随机5k子集之间的FID是29.6。这种差异可能是由于缺乏多样性或质量，或两者兼而有之。GAN-test，测量图像质量，在这两种情况下是相同的(95%)。而GAN-train从91%下降到80%，说明5k训练集缺乏多样性。我们的措施共同解决了FID的一个主要缺点。</p>
<p><strong>CIFAR100.</strong>表2总结了我们对CIFAR100的研究结果它是一个比CIFAR10更具挑战性的数据集，主要是因为类的数量更多，每个类的图像更少;从用真实图像训练的分类的准确性可以看出：CIFAR10和CIFAR100分别为92.8和69.4。SNGAN和WGAN-GP (10M)产生的IS和FID相似，但GAN-train和GAN-test精度相差很大。这使得SNGAN比WGAN-GP (10M)具有更好的图像质量和多样性。有趣的是，除了SWD，WGAN-GP (10M)在所有指标上都优于WGAN-GP (2.5M)。WGAN-GP(2.5M)达到了合理的IS和FID，但生成的样品质量很低，GAN-test的准确性证明了这一点。SWD的模式与CIFAR10的情况相同:WGAN-GP在这一指标上表现优于其他指标，这与其相对较差的图像质量并不一致。PixelCNN++表现出一种有趣的行为，GAN-test准确率很高，但是GAN-train准确率非常低，说明它可以生成质量可以接受的图像，但是缺乏多样性。在这种情况下的高FID也暗示了显著模式下降。我们还分析了在附录[5]中使用t-SNE[33]生成的图像的质量。</p>
<p><em>随机森林。</em>我们通过使用随机森林[23,43]而不是CNN进行分类来验证我们的发现是否取决于分类器的类型。结果GAN-train和GAN-test的分数分别为：SNGAN为15.2%，19.5%，WGAN-GP（10M）为10.9%，16.6%，WGAN-GP（2.5M）为3.7%，4.8%，DCGAN为3.2%，3.0%。注意，对于随机森林和cnn，这些GANs的相对排名是相同的。</p>
<p><em>人类的研究。</em>我们设计了一项人体研究，目的是找出哪些措施（如果有的话）更符合人类的判断。受试者被要求从为特定类别的CIFAR100生成的两个样本中选择更真实的图像。5名受试者在3个单独的测试中分别对SNGAN和DCGAN、WGAN-GP (2.5M)、WGAN-GP(10M)进行了评估。他们对每个测试随机生成的图像对进行了100次比较，即，总共1500次试验。他们都发现这个任务很有挑战性，特别是对于WGAN-GP测试。</p>
<p>&emsp;&emsp;我们使用学生t-test对这些结果进行统计分析。SNGAN VS DCGAN的500次试验中，受试者选择SNGAN 368次，SNGAN VS WGAN-GP (2.5M)的500次试验中，受试者选择SNGAN 274次，SNGAN VS　WGAN-GP (10M)的500次试验中，受试者选择SNGAN　230次。我们得出结论，所产生的图像质量需要非常不同，如SNGAN与DCGAN的情况一样，因为人类研究是决定性的。与我们的措施不同，它们不足以发现微妙但性能至关重要的差异。<br><em>ImageNet.</em>在此数据集上，我们基于CIFAR实验分析了两种最佳GAN模型的性能，即:SNGAN和WGAN-GP。如表3所示，SNGAN在128＊128分辨率下达到了合理的GAN-train精度和较高的GAN-test精度。这说明SNGAN生成的图像质量较好，但其多样性远低于原始数据。这可能部分是由于与ImageNet训练数据相比，发生器（150Mb）的尺寸明显更小。尽管尺寸存在差异，但前1和前5分类结果的GAN列精度分别达到9.3％和21.9％。相比之下，WGAN-GP的性能明显较差;表中每个分辨率见最后一行。<br><img src="https://user-images.githubusercontent.com/44546944/50210292-b0644700-03b0-11e9-9806-deae66b6b8cb.PNG" alt="6"></p>
<p>&emsp;&emsp;在64＊64分辨率下生成的图像中，使用SNGAN的GAN-train和GAN-test准确率低于128＊128。GAN-test精度是GAN-train的四倍以上，说明生成的图像缺乏多样性。有趣的是，WGAN-GP生成的Inception score和FID与SNGAN非常相似，但是它的图像不足以训练出一个合理的分类器，也不足以被ImageNet分类器识别，这一点可以从非常低的GAN-train和GAN-test score看出。</p>
<h3 id="5-３-GAN生成图像的多样性"><a href="#5-３-GAN生成图像的多样性" class="headerlink" title="5.３ GAN生成图像的多样性"></a><strong>5.３ GAN生成图像的多样性</strong></h3><p>&emsp;&emsp;我们通过评估不同数量的生成数据GAN-train精度进一步分析了生成的图像的多样性。多样性低的模型会产生冗余样本，在这种情况下，增加产生的数据量并不会提高GAN-train的精度。与此相反，从一个具有高度多样性的模型中生成更多的样本可以得到更好的GAN－train得分。我们在图4中显示了这种分析，其中GAN-train精度是根据CIFAR10和CIFAR100上生成的训练集的大小绘制的。</p>
<p>&emsp;&emsp;在CIFAR10的例子中，我们观察到GAN-train精度在生成图像的15-20k左右达到饱和，即使对于最好的模型SNGAN也是如此。（看图４）DCGAN比SNGAN弱，GAN-train由于多样性相对较差，在5k左右图像饱和。图4b显示，在CIFAR100上，除了25k图像外，所有模型的GAN-train精度没有增加。SNGAN生成的5k图像的多样性与真实图像的数量相当;参见图4b中的蓝色和橙色图。WGAN-GP (10M)的多样性非常低，超过5k生成的图像。WGAN-GP (2.5M)和DCGAN在CIFAR100上表现不佳，相对于其他方法没有竞争力。<br><img src="https://user-images.githubusercontent.com/44546944/50210776-f968cb00-03b1-11e9-8527-755ff265ff61.PNG" alt="7"></p>
<p>图4:改变生成的图像集大小对GAN－train精度的影响。为了便于比较，我们还用蓝色显示了改变实际图像训练数据集大小的结果。(pdf格式浏览效果最佳。)<br><img src="https://user-images.githubusercontent.com/44546944/50210995-7c8a2100-03b2-11e9-9f74-b36b1c4309be.PNG" alt="8"></p>
<center>图５使用真实和SNGAN生成的图像组合训练分类器的影响。</center>

<h3 id="5-４-GAN数据增强"><a href="#5-４-GAN数据增强" class="headerlink" title="5.４ GAN数据增强"></a><strong>5.４ GAN数据增强</strong></h3><p>&emsp;&emsp;我们分析了GANs在数据增强和生成额外训练样本方面的效用，其中GAN为在两种设置下使用性能最好的GAN模型(SNGAN)。首先，在图5a和5b中，我们展示了使用来自训练集的真实图像和分别在CIFAR10和CIFAR100数据集上GAN生成图像的组合的训练集，对分类器的影响。在这种情况下，使用原始训练集的所有图像训练模型SNGAN。 从这两个图中，我们观察到向50k的GAN生成图像中添加2.5k或5k真实像提高了只有真实时所对应的准确度。然而，添加50k的真实图像并没有带来任何明显的改进，事实上，CIFAR100稍微降低了性能(图5b)。这可能是由于缺乏图像的多样性。鉴于生成的图像是由从整个CIFAR10(或CIFAR100)训练数据集学习到的GAN生成的，本实验提供了另一个关于生成图像数据集多样性的视角。例如，将2.5k的真实图像与50k生成的图像相加，测试精度要优于仅对5k真实图像进行训练的模型。因此，我们可以得出GAN模型生成的图像比2.5k的真实图像具有更多的多样性。但是，假设生成的图像与原始数据一样真实。在实践中，生成的图像往往缺乏真实感，生成的图像比真实感更加丰富。这些意见与第5.3节的意见一致，即SNGAN生成的图像至少具有5k随机采样的真实图像的多样性<br>。</p>
<p>&emsp;&emsp;在第二种情况下，SNGAN是在低数据环境下训练的。与之前的实验不同，我们先在一个约简的训练集上训练SNGAN，然后在这个约简集和生成的图像数量相同的组合上训练分类器。表4的结果显示，CIFAR10和CIFAR100(表中分别为C10和C100)的行为与整个数据集设置(50k图像)一致，即，准确率略有下降。</p>
<p><img src="https://user-images.githubusercontent.com/44546944/50212254-8b260780-03b5-11e9-9d25-4ec1c91e9621.PNG" alt="9"></p>
<p>表4:用还原的真实图像集对SNGAN进行训练时的数据增强。分类器对该数据(真实)进行训练，或者结合真实和SNGAN生成的图像(真实+GAN)对分类器进行训练。性能以%精度表示。</p>
<h2 id="６-总结"><a href="#６-总结" class="headerlink" title="６　总结"></a><strong>６　总结</strong></h2><p>&emsp;&emsp;本文提出了一些步骤来解决由GANs生成的图像的评估和比较这一具有挑战性的问题。为此，我们提出了一种新的定量测量方法，即基于精度和召回率分数（常用于判别模型的评价）的GAN－train和GAN－test。我们评估了一些最近的GAN方法，以及其他流行的生成模型与这些措施。我们大量的实验分析表明，GAN-train和GAN-test不仅突出了这些方法在性能上的差异，而且是对现有分数的补充。</p>

      
    </div>
    
    
    

    

    
      <div>
        <div style="padding: 10px 0; margin: 20px auto; width: 90%; text-align: center;">
  <div>给个糖呗~</div>
  <button id="rewardButton" disable="enable" onclick="var qr = document.getElementById('QR'); if (qr.style.display === 'none') {qr.style.display='block';} else {qr.style.display='none'}">
    <span>打赏</span>
  </button>
  <div id="QR" style="display: none;">

    
      <div id="wechat" style="display: inline-block">
        <img id="wechat_qr" src="/images/wechat_code.jpg" alt="朱越 微信支付">
        <p>微信支付</p>
      </div>
    

    
      <div id="alipay" style="display: inline-block">
        <img id="alipay_qr" src="/images/alipay_code.png" alt="朱越 支付宝">
        <p>支付宝</p>
      </div>
    

    

  </div>
</div>

      </div>
    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/gan/" rel="tag"># gan</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/11/25/HEXO常用命令/" rel="next" title="HEXO常用命令">
                <i class="fa fa-chevron-left"></i> HEXO常用命令
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2018/12/20/Explaining-and-Harnessing-Adversarial-Example/" rel="prev" title="Explaining and Harnessing Adversarial Example">
                Explaining and Harnessing Adversarial Example <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image" src="/images/logo.jpg" alt="朱越">
            
              <p class="site-author-name" itemprop="name">朱越</p>
              <p class="site-description motion-element" itemprop="description">记录学习，记录生活</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">4</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">3</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/zhuyue123" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="845898052@qq.com" target="_blank" title="E-Mail">
                      
                        <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#How-good-is-my-GAN-学习笔记"><span class="nav-number">1.</span> <span class="nav-text">How good is my GAN 学习笔记</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-引言"><span class="nav-number">1.1.</span> <span class="nav-text">1 引言</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-相关工作"><span class="nav-number">1.2.</span> <span class="nav-text">2 相关工作</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#2-1-Inception-score"><span class="nav-number">1.2.1.</span> <span class="nav-text">2.1 Inception score</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-2-Frechet-Inception-distance"><span class="nav-number">1.2.2.</span> <span class="nav-text">2.2 Frechet Inception distance</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-3-其他评价方法"><span class="nav-number">1.2.3.</span> <span class="nav-text">2.3 其他评价方法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-4-数据增强"><span class="nav-number">1.2.4.</span> <span class="nav-text">2.4 数据增强</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-GAN-train和GAN-test"><span class="nav-number">1.3.</span> <span class="nav-text">3 GAN-train和GAN-test</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-数据集和方法"><span class="nav-number">1.4.</span> <span class="nav-text">4 数据集和方法</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#4-1-评估方法"><span class="nav-number">1.4.1.</span> <span class="nav-text">4.1 评估方法</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5-实验"><span class="nav-number">1.5.</span> <span class="nav-text">5 实验</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#5-1-评估措施实施细则"><span class="nav-number">1.5.1.</span> <span class="nav-text">5.1 评估措施实施细则</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-2-生成模型评价"><span class="nav-number">1.5.2.</span> <span class="nav-text">5.2 生成模型评价</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-３-GAN生成图像的多样性"><span class="nav-number">1.5.3.</span> <span class="nav-text">5.３ GAN生成图像的多样性</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-４-GAN数据增强"><span class="nav-number">1.5.4.</span> <span class="nav-text">5.４ GAN数据增强</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#６-总结"><span class="nav-number">1.6.</span> <span class="nav-text">６　总结</span></a></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-囡"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">朱越</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Gemini</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  


  



  
  



  
  



  
  





  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  

  
  
    <script type="text/javascript" src="/lib/canvas-nest/canvas-nest.min.js"></script>
  

  
  
    <script type="text/javascript" src="/lib/three/three.min.js"></script>
  

  
  
    <script type="text/javascript" src="/lib/three/three-waves.min.js"></script>
  

  
  
    <script type="text/javascript" src="/lib/three/canvas_lines.min.js"></script>
  

  
  
    <script type="text/javascript" src="/lib/three/canvas_sphere.min.js"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  
  <script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.4.js"></script>
  <script>AV.initialize("xodhWcqwVlNKwXpkcoLVq9Nf-gzGzoHsz", "U57AUgqscBJJ3NzdutErypfu");</script>
  <script>
    function showTime(Counter) {
      var query = new AV.Query(Counter);
      var entries = [];
      var $visitors = $(".leancloud_visitors");

      $visitors.each(function () {
        entries.push( $(this).attr("id").trim() );
      });

      query.containedIn('url', entries);
      query.find()
        .done(function (results) {
          var COUNT_CONTAINER_REF = '.leancloud-visitors-count';

          if (results.length === 0) {
            $visitors.find(COUNT_CONTAINER_REF).text(0);
            return;
          }

          for (var i = 0; i < results.length; i++) {
            var item = results[i];
            var url = item.get('url');
            var time = item.get('time');
            var element = document.getElementById(url);

            $(element).find(COUNT_CONTAINER_REF).text(time);
          }
          for(var i = 0; i < entries.length; i++) {
            var url = entries[i];
            var element = document.getElementById(url);
            var countSpan = $(element).find(COUNT_CONTAINER_REF);
            if( countSpan.text() == '') {
              countSpan.text(0);
            }
          }
        })
        .fail(function (object, error) {
          console.log("Error: " + error.code + " " + error.message);
        });
    }

    function addCount(Counter) {
      var $visitors = $(".leancloud_visitors");
      var url = $visitors.attr('id').trim();
      var title = $visitors.attr('data-flag-title').trim();
      var query = new AV.Query(Counter);

      query.equalTo("url", url);
      query.find({
        success: function(results) {
          if (results.length > 0) {
            var counter = results[0];
            counter.fetchWhenSave(true);
            counter.increment("time");
            counter.save(null, {
              success: function(counter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(counter.get('time'));
              },
              error: function(counter, error) {
                console.log('Failed to save Visitor num, with error message: ' + error.message);
              }
            });
          } else {
            var newcounter = new Counter();
            /* Set ACL */
            var acl = new AV.ACL();
            acl.setPublicReadAccess(true);
            acl.setPublicWriteAccess(true);
            newcounter.setACL(acl);
            /* End Set ACL */
            newcounter.set("title", title);
            newcounter.set("url", url);
            newcounter.set("time", 1);
            newcounter.save(null, {
              success: function(newcounter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(newcounter.get('time'));
              },
              error: function(newcounter, error) {
                console.log('Failed to create');
              }
            });
          }
        },
        error: function(error) {
          console.log('Error:' + error.code + " " + error.message);
        }
      });
    }

    $(function() {
      var Counter = AV.Object.extend("Counter");
      if ($('.leancloud_visitors').length == 1) {
        addCount(Counter);
      } else if ($('.post-title-link').length > 1) {
        showTime(Counter);
      }
    });
  </script>



  

  

  
  

  
  


  

  

</body>
</html>
